{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:autolab_core not installed as catkin package, RigidTransform ros methods will be unavailable\n",
      "WARNING:root:Unable to import CNN modules! Likely due to missing tensorflow.\n",
      "WARNING:root:TensorFlow can be installed following the instructions in https://www.tensorflow.org/get_started/os_setup\n",
      "WARNING:root:Unable to import pylibfreenect2. Python-only Kinect driver may not work properly.\n",
      "WARNING:root:Unable to import openni2 driver. Python-only Primesense driver may not work properly\n",
      "WARNING:root:Failed to import ROS in phoxi_sensor.py. PhoXiSensor functionality unavailable.\n"
     ]
    }
   ],
   "source": [
    "# PYTHON NAITIVE\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import struct\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# ROS\n",
    "from sensor_msgs.msg import CameraInfo, Image\n",
    "from cv_bridge import CvBridge, CvBridgeError\n",
    "\n",
    "# GQCNN\n",
    "from autolab_core import YamlConfig, Logger\n",
    "import autolab_core.utils as utils\n",
    "# from gqcnn import get_gqcnn_model, get_gqcnn_trainer, utils as gqcnn_utils\n",
    "from perception import (BinaryImage, CameraIntrinsics, ColorImage, DepthImage,\n",
    "                        RgbdImage)\n",
    "from visualization import Visualizer2D as vis\n",
    "# from gqcnn.grasping import (RobustGraspingPolicy,\n",
    "#                             CrossEntropyRobustGraspingPolicy, RgbdImageState,\n",
    "#                             FullyConvolutionalGraspingPolicyParallelJaw,\n",
    "#                             FullyConvolutionalGraspingPolicySuction)\n",
    "# from gqcnn.utils import GripperMode\n",
    "\n",
    "# GQCNN Networks\n",
    "# from policy_mujoco import GQCNN\n",
    "# from grasp_network import VPNET\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# CUSTOM PACKAGES\n",
    "from baxter_robot import BaxterRobot\n",
    "from custom_realsense_sensor import RealSenseSensor\n",
    "from realrobot_utils import *\n",
    "from greedy_agent import *\n",
    "\n",
    "# FOR VISUALIZATION\"\n",
    "import mpld3\n",
    "from mpld3 import plugins\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] [1613814500.628909]: Robot Enabled\n",
      "[INFO] [1613814503.145556]: Robot Enabled\n"
     ]
    }
   ],
   "source": [
    "rospy.init_node(\"collecting_6dof_realrobot_grasping_data\")\n",
    "realsense = RealSenseSensor(\"826212070576\",frame='realsense')\n",
    "camera_1 = RealSenseSensor(\"023422073834\",frame='realsense')\n",
    "camera_2 = RealSenseSensor(\"025222072118\",frame='realsense')\n",
    "baxter_right_arm = BaxterRobot('right',ik_trials=10)\n",
    "baxter_left_arm = BaxterRobot('left',ik_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving the right arm to the pose...\n",
      "Moving the right arm to the pose...\n",
      "Moving the right arm to the pose...\n",
      "Moving the right arm to the pose...\n"
     ]
    }
   ],
   "source": [
    "calibration_joint_angles = [{'right_e0': 0.19251458887961942,\n",
    " 'right_e1': 0.6189612479117644,\n",
    " 'right_s0': 0.6254806662602774,\n",
    " 'right_s1': -0.9541360500647273,\n",
    " 'right_w0': -0.19059711289476267,\n",
    " 'right_w1': 2.063971150099824,\n",
    " 'right_w2': -0.15378157398551273},\n",
    "                            {'right_e0': 1.2742698569762068,\n",
    " 'right_e1': 1.4520600494823506,\n",
    " 'right_s0': -0.08169290290373594,\n",
    " 'right_s1': -1.1523049914420582,\n",
    " 'right_w0': -0.4056283485977753,\n",
    " 'right_w1': 1.5620040784992788,\n",
    " 'right_w2': 0.3882446109795593},\n",
    "                           {'right_e0': 0.6860729073817513,\n",
    " 'right_e1': 1.2060923944749065,\n",
    " 'right_s0': -0.3746748074410123,\n",
    " 'right_s1': -1.430053589506177,\n",
    " 'right_w0': 0.16835439147042416,\n",
    " 'right_w1': 1.8917818066596865,\n",
    " 'right_w2': -0.7389952445637981},\n",
    "                           {'right_e0': 0.19711653124327566,\n",
    " 'right_e1': 0.9644904203829539,\n",
    " 'right_s0': 0.17640779060682257,\n",
    " 'right_s1': -1.1332283070503495,\n",
    " 'right_w0': 0.18791264651596318,\n",
    " 'right_w1': 1.8676216092504911,\n",
    " 'right_w2': -0.5376602661538376}]\n",
    "\n",
    "\n",
    "p_realsense_to_endpoints = []\n",
    "quat_realsense_to_endpoints = []\n",
    "bin_heights = []\n",
    "for calibration_joint_angle in calibration_joint_angles:\n",
    "    baxter_right_arm.move_to_joint_angles(calibration_joint_angle)\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            T_realsense_to_endpoint, _, T_base_to_chess = robot_realsense_calibration(baxter_right_arm, realsense, CHECKER_COLS = 9, CHECKER_ROWS = 6, SQUARE_SIZE = 0.025, show_images=False)\n",
    "        except:\n",
    "            T_realsense_to_endpoint, _, T_base_to_chess = robot_realsense_calibration(baxter_right_arm, realsense, CHECKER_COLS = 9, CHECKER_ROWS = 6, SQUARE_SIZE = 0.025, show_images=True)\n",
    "            \n",
    "        R_realsense_to_endpoint, p_realsense_to_endpoint = get_Rp_from_T(T_realsense_to_endpoint)\n",
    "        p_realsense_to_endpoints.append(p_realsense_to_endpoint)\n",
    "        quat_realsense_to_endpoint = quaternion_from_matrix(rot3x3_to_4x4(R_realsense_to_endpoint))\n",
    "        quat_realsense_to_endpoints.append(quat_realsense_to_endpoint)\n",
    "        _, p_base_to_chess = get_Rp_from_T(T_base_to_chess)\n",
    "        bin_heights.append(p_base_to_chess[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.03984073 -0.998733   -0.0307427   0.01483392]\n",
      " [ 0.99909574 -0.04027461  0.01362544  0.05759827]\n",
      " [-0.01484632 -0.03017205  0.99943446  0.12677811]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "[[-0.03984073 -0.998733   -0.0307427   0.00483392]\n",
      " [ 0.99909574 -0.04027461  0.01362544  0.08259827]\n",
      " [-0.01484632 -0.03017205  0.99943446  0.09677811]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "-0.17006824056096756\n"
     ]
    }
   ],
   "source": [
    "quat_realsense_to_endpoint = np.median(quat_realsense_to_endpoints, axis=0)\n",
    "p_realsense_to_endpoint = np.median(p_realsense_to_endpoints, axis=0)\n",
    "R_realsense_to_endpoint = quaternion_matrix(quat_realsense_to_endpoint)[:3,:3]\n",
    "T_realsense_to_endpoint = form_T(R_realsense_to_endpoint, p_realsense_to_endpoint)\n",
    "print(T_realsense_to_endpoint)\n",
    "\n",
    "T_realsense_to_endpoint[0,3] -= 0.01\n",
    "T_realsense_to_endpoint[1,3] += 0.025\n",
    "T_realsense_to_endpoint[2,3] -= 0.03\n",
    "\n",
    "bin_height = np.mean(bin_heights)\n",
    "print(T_realsense_to_endpoint)\n",
    "print(bin_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving the right arm to the pose...\n",
      "[ 0.56740173 -0.29283392  0.38315365]\n",
      "Point(x=0.5674740118233019, y=-0.2906140216193931, z=0.3837165775151905)\n",
      "[ 0.02003569  0.99965784  0.0152339  -0.00712038]\n",
      "Quaternion(x=0.01872067021839483, y=0.9996534745378176, z=0.016991185101320836, w=-0.007332597077138134)\n",
      "{'right_s0': -0.27729115716620595, 'right_s1': -1.3380035233003633, 'right_w0': -0.19874101401935695, 'right_w1': 1.6872687249320877, 'right_w2': 0.24728247862408442, 'right_e0': 1.2960948822826435, 'right_e1': 1.3940321166118148}\n"
     ]
    }
   ],
   "source": [
    "init_realsense_position = np.array([[0.65, -0.288, 0.65+bin_height]]).T\n",
    "init_realsense_quaternion = np.array([ 0.70710678, -0.70710678, 0., 0.])\n",
    "\n",
    "T_base_to_new_realsense = form_T(quaternion_matrix(init_realsense_quaternion)[:3,:3], init_realsense_position)\n",
    "T_base_to_new_endpoint = T_base_to_new_realsense.dot(T_realsense_to_endpoint)\n",
    "\n",
    "init_eef_position = T_base_to_new_endpoint[:3,3]\n",
    "init_eef_quaternion = quaternion_from_matrix(T_base_to_new_endpoint)\n",
    "init_eef_jointangles = baxter_right_arm.move_to_pose(init_eef_position, init_eef_quaternion)\n",
    "current_eef_pose = baxter_right_arm._limb.endpoint_pose()\n",
    "baxter_right_arm.gripper_open()\n",
    "\n",
    "print(init_eef_position.T)\n",
    "print(current_eef_pose['position'])\n",
    "print(init_eef_quaternion)\n",
    "print(current_eef_pose['orientation'])\n",
    "print(init_eef_jointangles)\n",
    "\n",
    "# raw_input(\"Remove the chessboard and place the bin. Are you done?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_block_pos():\n",
    "    print('########################### GO TO INITIAL ###########################################')\n",
    "    init_eef_jointangles = baxter_right_arm.move_to_pose(init_eef_position, init_eef_quaternion)\n",
    "    current_eef_pose = baxter_right_arm._limb.endpoint_pose()\n",
    "    baxter_right_arm.gripper_open()\n",
    "\n",
    "    print('########################### FIND A BLOCK ###########################################')\n",
    "    K_realsense, D_realsense = realsense.get_realsense_camera_K_and_D()\n",
    "    bin_input_rgb_im, bin_input_depth_im, _, _, bin_depth_im, _= get_input_rgbd_image(realsense, crop_size = 430, resize_width = 256, resize_height = 256)\n",
    "\n",
    "    rgb_= copy.deepcopy(bin_input_rgb_im)\n",
    "    _, edged = cv2.threshold(rgb_[:,:,0],20,255, cv2.THRESH_BINARY_INV)\n",
    "    plt.imshow(edged)\n",
    "    plt.show()\n",
    "\n",
    "    center_x, center_y = None, None\n",
    "    _, contours, _ = cv2.findContours(edged, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        if 600 < w*h < 1200:\n",
    "            print(w*h)\n",
    "            cv2.rectangle(rgb_,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            center_x = x + w//2\n",
    "            center_y = y + h//2\n",
    "            cv2.circle(rgb_, (center_x, center_y), 2, (255, 0, 0), 1)\n",
    "    plt.imshow(rgb_)\n",
    "    plt.show()\n",
    "\n",
    "    if center_x is None or center_y is None:\n",
    "        print('ERROR: Cannot find the block!!')\n",
    "\n",
    "    print('########################### FIND BLOCK POS ###################################')\n",
    "    endpoint_pose_base = baxter_right_arm._limb.endpoint_pose()\n",
    "    T_base_to_endpoint = get_transformation_from_pose(endpoint_pose_base)\n",
    "    T_endpoint_to_realsense = np.linalg.inv(T_realsense_to_endpoint)\n",
    "\n",
    "    midx, midy = realsense._intrinsics[:2,2]\n",
    "\n",
    "    pixel = np.array([center_x, center_y], np.int32)\n",
    "    psi = 0.0\n",
    "    grasp_depth = 0.68\n",
    "    raw_pixel = inverse_raw_pixel(pixel, midx, midy, cs=430)\n",
    "    diff_endpoint_position_realsense = inverse_projection(bin_depth_im, raw_pixel, K_realsense, D_realsense)\n",
    "    diff_endpoint_position_realsense[2] = grasp_depth\n",
    "    diff_endpoint_quaternion_realsense = quaternion_from_matrix(T_realsense_to_endpoint.dot(rotation_matrix(psi, [0.,0.,1.])))\n",
    "\n",
    "    T_realsense_to_new_endpoint = form_T(quaternion_matrix(diff_endpoint_quaternion_realsense)[:3,:3], diff_endpoint_position_realsense)\n",
    "    T_base_to_new_endpoint =T_base_to_endpoint.dot(T_endpoint_to_realsense.dot(T_realsense_to_new_endpoint))\n",
    "    goal_eef_position = T_base_to_new_endpoint[:3,3]\n",
    "    print('Goal EEF position', goal_eef_position)\n",
    "    \n",
    "    return goal_eef_position, center_x, center_y\n",
    "\n",
    "def check_grasp():\n",
    "    endeff_torque = baxter_right_arm._gripper.force()\n",
    "    if endeff_torque > 25.:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_pixel(center_x, center_y):\n",
    "    pixel = np.array([center_x, center_y], np.int32)\n",
    "    grasp_depth = 0.70\n",
    "    psi = 0.0\n",
    "    midx, midy = realsense._intrinsics[:2,2]\n",
    "    raw_pixel = inverse_raw_pixel(pixel, midx, midy, cs=430)\n",
    "    \n",
    "    endpoint_pose_base = baxter_right_arm._limb.endpoint_pose()\n",
    "    T_base_to_endpoint = get_transformation_from_pose(endpoint_pose_base)\n",
    "    T_endpoint_to_realsense = np.linalg.inv(T_realsense_to_endpoint)\n",
    "    \n",
    "    K_realsense, D_realsense = realsense.get_realsense_camera_K_and_D()\n",
    "    bin_input_rgb_im, bin_input_depth_im, _, _, bin_depth_im, _= get_input_rgbd_image(realsense, crop_size = 430, resize_width = 256, resize_height = 256)\n",
    "    \n",
    "    diff_endpoint_position_realsense = inverse_projection(bin_depth_im, raw_pixel, K_realsense, D_realsense)\n",
    "    diff_endpoint_position_realsense[2] = grasp_depth\n",
    "    diff_endpoint_quaternion_realsense = quaternion_from_matrix(T_realsense_to_endpoint.dot(rotation_matrix(psi, [0.,0.,1.])))\n",
    "    \n",
    "    T_realsense_to_new_endpoint = form_T(quaternion_matrix(diff_endpoint_quaternion_realsense)[:3,:3], diff_endpoint_position_realsense)\n",
    "    T_base_to_new_endpoint =T_base_to_endpoint.dot(T_endpoint_to_realsense.dot(T_realsense_to_new_endpoint))\n",
    "    goal_eef_position = T_base_to_new_endpoint[:3,3]\n",
    "    goal_eef_quaternion = quaternion_from_matrix(T_base_to_new_endpoint)\n",
    "    goal_eef_jointangles = baxter_right_arm.move_to_pose(goal_eef_position+[0.0, 0.0, 0.05], goal_eef_quaternion, timeout=10.0)\n",
    "    goal_eef_jointangles = baxter_right_arm.move_to_pose(goal_eef_position, goal_eef_quaternion, timeout=10.0)\n",
    "    \n",
    "    return goal_eef_position\n",
    "    \n",
    "def get_curr_eef_pos():\n",
    "    endpoint_pose_base = baxter_right_arm._limb.endpoint_pose()\n",
    "    T_base_to_endpoint = get_transformation_from_pose(endpoint_pose_base)\n",
    "    return T_base_to_endpoint[:3, 3]\n",
    "\n",
    "def rl_step(action, curr_grasp):\n",
    "    eef_pos = get_curr_eef_pos()\n",
    "    mov_dist = 0.03\n",
    "    z_min = -0.23674\n",
    "    grasp = curr_grasp\n",
    "    if action<10:\n",
    "        if action < 8:\n",
    "            mov_degree = action * np.pi / 4.0\n",
    "            eef_pos = eef_pos + np.array([mov_dist * np.cos(mov_degree), mov_dist * np.sin(mov_degree), 0.0])\n",
    "        elif action == 8:\n",
    "            eef_pos = eef_pos + np.array([0.0, 0.0, mov_dist])\n",
    "        elif action == 9:\n",
    "            eef_pos = eef_pos + np.array([0.0, 0.0, -mov_dist])\n",
    "            if eef_pos[2] < z_min:\n",
    "                eef_pos[2] = z_min\n",
    "        init_eef_jointangles = baxter_right_arm.move_to_pose(eef_pos, init_eef_quaternion, timeout=3.0)\n",
    "    else:\n",
    "        if action == 10:\n",
    "            baxter_right_arm.gripper_close()\n",
    "            grasp = 1.0\n",
    "        elif action == 11:\n",
    "            baxter_right_arm.gripper_open()\n",
    "            grasp = 0.0\n",
    "    rospy.sleep(0.1)\n",
    "    new_eef_pos = get_curr_eef_pos()\n",
    "    return new_eef_pos, grasp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(cam_1, cam_2):\n",
    "    rgb_1, depth_1, _, _, _, _= get_input_rgbd_image(cam_1, crop_size = 430, resize_width = 128, resize_height = 128)\n",
    "    rgb_2, depth_2, _, _, _, _= get_input_rgbd_image(cam_2, crop_size = 430, resize_width = 128, resize_height = 128)\n",
    "    state = np.zeros([128, 128, 8])\n",
    "    state[:, :, :3] = rgb_1/255\n",
    "    state[:, :, 3] = np.clip(depth_1, 0.0, 5.0)\n",
    "    state[:, :, 4:7] = rgb_2/255\n",
    "    state[:, :, 7] = np.clip(depth_2, 0.0, 5.0)\n",
    "    return state\n",
    "\n",
    "def record_state(buff_a, buff_s, buff_d, task):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'place' # 'reach', 'pick', 'place'\n",
    "mov_dist = 0.03\n",
    "agent = GreedyAgent(task=task, mov_dist=mov_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spawn_range = 0.0\n",
    "baxter_right_arm.gripper_open()\n",
    "goal_eef_position, center_x, center_y = find_block_pos()\n",
    "\n",
    "if task=='reach':\n",
    "    start_pos = init_eef_position.copy()\n",
    "    start_pos[0] -= 0.15\n",
    "    start_pos[2] = -0.20\n",
    "    start_pos[:2] += spawn_range * np.random.uniform(low=-1.0, high=1.0, size=2)\n",
    "    goal_pos = goal_eef_position\n",
    "    baxter_right_arm.move_to_pose(start_pos, init_eef_quaternion, timeout=5.0)\n",
    "    baxter_right_arm.gripper_close()\n",
    "    curr_grasp = 1.0\n",
    "elif task=='pick':\n",
    "    start_pos = init_eef_position.copy()\n",
    "    start_pos[0] -= 0.15\n",
    "    start_pos[2] = -0.10\n",
    "    start_pos[:2] += spawn_range * np.random.uniform(low=-1.0, high=1.0, size=2)\n",
    "    goal_pos = goal_eef_position\n",
    "    baxter_right_arm.move_to_pose(start_pos, init_eef_quaternion, timeout=5.0)\n",
    "    baxter_right_arm.gripper_open()\n",
    "    curr_grasp = 0.0\n",
    "elif task=='place':\n",
    "    start_pos = np.zeros(3)\n",
    "    start_pos = move_to_pixel(center_x, center_y)\n",
    "    start_z = start_pos[2]\n",
    "    start_pos[2] = -0.10\n",
    "    goal_pos = np.array([0.75, -0.30, start_z])\n",
    "    baxter_right_arm.gripper_close()\n",
    "    baxter_right_arm.move_to_pose(start_pos, init_eef_quaternion, timeout=5.0)\n",
    "    curr_grasp = 1.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving the right arm to the pose...\n"
     ]
    }
   ],
   "source": [
    "curr_pos = get_curr_eef_pos()\n",
    "success = False\n",
    "\n",
    "buff_action = []\n",
    "buff_state = []\n",
    "buff_done = []\n",
    "while True:\n",
    "    action = agent.get_action(curr_pos, goal_pos, curr_grasp)\n",
    "    curr_pos, curr_grasp = rl_step(action, curr_grasp)\n",
    "    state = get_state(camera_1, camera_2)\n",
    "    print(action, curr_grasp)\n",
    "    \n",
    "    buff_action.append(action)\n",
    "    buff_state.append(state)\n",
    "    \n",
    "    if task=='reach' and np.linalg.norm(curr_pos - goal_pos) < mov_dist/2:\n",
    "        success = True\n",
    "    if task=='pick' and curr_pos[2] > -0.18 and check_grasp():\n",
    "        success = True\n",
    "    if task=='place' and np.linalg.norm(curr_pos - goal_pos) < mov_dist/2:\n",
    "        success = True\n",
    "    if success:\n",
    "        print('Success!!')\n",
    "        buff_done.append(1)\n",
    "        break\n",
    "    else:\n",
    "        buff_done.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving the right arm to the pose...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'right_e0': 1.2075328019027234,\n",
       " 'right_e1': 1.7853791072502672,\n",
       " 'right_s0': -0.21821528391596315,\n",
       " 'right_s1': -0.20921187387599413,\n",
       " 'right_w0': -1.4443574766555198,\n",
       " 'right_w1': 1.187141909316366,\n",
       " 'right_w2': 0.7249360606401783}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if success:\n",
    "    record_state(buff_action, buff_state, buff_done, task)\n",
    "\n",
    "if task=='reach':\n",
    "    pass\n",
    "elif task=='pick':\n",
    "    place_pos = np.zeros(3)\n",
    "    place_pos[:2] = curr_pos[:2]\n",
    "    place_pos[2] = -0.20\n",
    "    baxter_right_arm.move_to_pose(place_pos, init_eef_quaternion, timeout=5.0)\n",
    "    baxter_right_arm.gripper_open()\n",
    "elif task=='place':\n",
    "    baxter_right_arm.gripper_open()\n",
    "baxter_right_arm.move_to_pose(start_pos, init_eef_quaternion, timeout=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/dof6/catkin_ws/src/samsung_manipulation/scripts/brain_data\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini",
   "language": "python",
   "name": "minienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
